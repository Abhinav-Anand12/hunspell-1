% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hunspell.R
\name{hunspell_check}
\alias{dicpath}
\alias{en_stats}
\alias{hunspell}
\alias{hunspell_analyze}
\alias{hunspell_check}
\alias{hunspell_find}
\alias{hunspell_info}
\alias{hunspell_stem}
\alias{hunspell_suggest}
\title{Hunspell Spell Checking}
\usage{
hunspell_check(words, ignore = en_stats, dict = "en_US")

hunspell_find(text, ignore = en_stats, format = c("text", "man", "latex"),
  dict = "en_US")

hunspell_suggest(words, dict = "en_US")

hunspell_analyze(words, dict = "en_US")

hunspell_stem(words, dict = "en_US")

hunspell_info(dict = "en_US")
}
\arguments{
\item{words}{character vector with individual words to spellcheck}

\item{ignore}{character vector with additional approved words for the dictionary.
The default is \code{en_stats} which is included with base R.}

\item{dict}{dictionary language, see details}

\item{text}{character vector with arbitrary input text}

\item{format}{input format; supported parsers are \code{text}, \code{latex} or \code{man}}
}
\description{
The \code{\link{hunspell_check}} function takes a vector of words and checks
each individual word for correctness. The \code{\link{hunspell_find}} function
takes a character vector with text (in plain, latex or man format) and returns
a list with incorrect words for each line. Finally \code{\link{hunspell_suggest}}
is used to suggest correct alternatives for each (incorrect) input word.
}
\details{
The \code{\link{hunspell_analyze}} function shows how a word breaks down into a
valid stem plus affix. The \code{\link{hunspell_stem}} function only returns valid
stems for a given word. Hunspell uses a special dictionary format that defines
which stems and affixes are valid in a given language. Among other things, stemming
can be used to summarize text (e.g wordcloud).

The package searches in the standard system locations for dictionaries. Additional
custom search paths can be added by setting the \code{DICPATH} environment variable.
A US english dictionary is included with the package; other dictionaries need to
be installed by the system. Most distributions include standard dictionaries, such
as \href{https://packages.debian.org/sid/hunspell-en-gbl}{hunspell-en-gb} or
\href{https://packages.debian.org/sid/myspell-en-gb}{myspell-en-gb}.
To manually install dictionaries, download the \code{.aff} and \code{.dic} file
from an OpenOffice \href{http://ftp.snt.utwente.nl/pub/software/openoffice/contrib/dictionaries/}{mirror}
or \href{http://archive.ubuntu.com/ubuntu/pool/main/libr/libreoffice-dictionaries/?C=S;O=D}{bundle}.
and copy them to \code{~/Library/Spelling} or a custom directory specified in \code{DICPATH}.

Note that \code{hunspell_find} uses iconv to convert input text to the encoding
used by the specified dictionary. This will fail if \code{text} contains characters
which are not supported by the encoding. For this reason it is safest to use UTF8
dictionaries which can represent all unicode characters. Several UTF8 dictionaries are
available from \href{https://github.com/titoBouzout/Dictionaries}{Github}.
}
\examples{
#check individual words
words <- c("beer", "wiskey", "wine")
correct <- hunspell_check(words)
print(correct)

# find suggestions for incorrect words
hunspell_suggest(words[!correct])

# find incorrect words in piece of text
bad <- hunspell_find("spell checkers are not neccessairy for langauge ninja's")
print(bad[[1]])
hunspell_suggest(bad[[1]])

# check a latex document
setwd(tempdir())
download.file("http://arxiv.org/e-print/1406.4806v1", "1406.4806v1.tar.gz",  mode = "wb")
untar("1406.4806v1.tar.gz")
text <- readLines("content.tex", warn = FALSE)
words <- hunspell_find(text, format = "latex")
sort(unique(unlist(words)))
}

