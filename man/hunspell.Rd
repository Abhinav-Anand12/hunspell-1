% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/hunspell.R
\name{hunspell_find}
\alias{dicpath}
\alias{en_stats}
\alias{hunspell}
\alias{hunspell_analyze}
\alias{hunspell_check}
\alias{hunspell_find}
\alias{hunspell_info}
\alias{hunspell_stem}
\alias{hunspell_suggest}
\title{Hunspell Spell Checking}
\usage{
hunspell_find(text, format = c("text", "man", "latex"), dict = "en_US",
  ignore = en_stats)

hunspell_check(words, dict = "en_US")

hunspell_suggest(words, dict = "en_US")

hunspell_analyze(words, dict = "en_US")

hunspell_stem(words, dict = "en_US")

hunspell_info(dict = "en_US")
}
\arguments{
\item{text}{character vector with arbitrary input text}

\item{format}{input format; supported parsers are \code{text}, \code{latex} or \code{man}}

\item{dict}{dictionary language, see details}

\item{ignore}{character vector with additional approved words added to the dictionary}

\item{words}{character vector with individual words to spell check}
}
\description{
The \code{\link{hunspell_find}} function takes a character vector
with text (plain, latex or man format), parses out the words and returns a list
with incorrect words for each line. See details for low-level operations
on individual words.
}
\details{
Hunspell uses a special dictionary format that defines which stems and affixes are
valid in a given language. The \code{\link{hunspell_analyze}} function shows how a
word breaks down into a valid stem plus affix. The \code{\link{hunspell_stem}}
function is similar but only returns valid stems for a given word. Stemming can be
used to summarize text (e.g in a wordcloud). The \code{\link{hunspell_check}} function
takes a vector of individual words and tests each one for correctness. Finally
\code{\link{hunspell_suggest}} is used to suggest correct alternatives for each
(incorrect) input word.

The package searches for dictionaries in the working directory as well as in the
standard system locations. Additional search paths can be specified by setting
the \code{DICPATH} environment variable. A US English dictionary (\code{en_US}) is
included with the package; other dictionaries need to be installed by the system.
Most operating systems already include compatible dictionaries with names such as
\href{https://packages.debian.org/sid/hunspell-en-gb}{hunspell-en-gb} or
\href{https://packages.debian.org/sid/myspell-en-gb}{myspell-en-gb}.

To manually install dictionaries, download the \code{.aff} and \code{.dic} file
from an OpenOffice \href{http://ftp.snt.utwente.nl/pub/software/openoffice/contrib/dictionaries/}{mirror}
or \href{http://archive.ubuntu.com/ubuntu/pool/main/libr/libreoffice-dictionaries/?C=S;O=D}{bundle}
and copy them to \code{~/Library/Spelling} or a custom directory specified in \code{DICPATH}.
Alternatively you can pass the entire path to the \code{.dic} file as the \code{dict}
parameter.

Note that \code{hunspell_find} uses \code{\link{iconv}} to convert input text to
the encoding used by the dictionary. This will fail if \code{text} contains characters
which are unsupported by that particular encoding. For this reason UTF-8 dictionaries
are preferable over legacy 8bit dictionaries Several UTF8 dictionaries are
available from \href{https://github.com/titoBouzout/Dictionaries}{Github}.
}
\examples{
# Check individual words
words <- c("beer", "wiskey", "wine")
correct <- hunspell_check(words)
print(correct)

# Find suggestions for incorrect words
hunspell_suggest(words[!correct])

# Extract incorrect from a piece of text
bad <- hunspell_find("spell checkers are not neccessairy for langauge ninja's")
print(bad[[1]])
hunspell_suggest(bad[[1]])

# Check an entire latex document
setwd(tempdir())
download.file("http://arxiv.org/e-print/1406.4806v1", "1406.4806v1.tar.gz",  mode = "wb")
untar("1406.4806v1.tar.gz")
text <- readLines("content.tex", warn = FALSE)
words <- hunspell_find(text, format = "latex")
sort(unique(unlist(words)))
}

